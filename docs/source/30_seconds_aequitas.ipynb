{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Welcome to Aequitas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The Aequitas toolkit is a flexible bias-audit utility for algorithmic decision-making models, accessible via Python API, command line interface (CLI), and through our [web application](http://aequitas.dssg.io/). \n",
    "\n",
    "Use Aequitas to evaluate model performance across several bias and fairness metrics, and utilize the [most relevant metrics](https://dsapp.uchicago.edu/wp-content/uploads/2018/05/metrictree-1200x750.png) to your process in model selection.\n",
    "\n",
    "Aequitas will help you:\n",
    "\n",
    "- Understand where any error-related biases exist in your model(s)\n",
    "- Compare the level of bias between groups in your sample population (bias disparity)\n",
    "- Visualize absolute bias metrics and their related disparities for rapid comprehension and decision-making\n",
    "\n",
    "Our goal is to support informed and equitable action for both machine learnining practitioners and the decision-makers who rely on them.\n",
    "\n",
    "Read the [documentation](https://dssg.github.io/aequitas/).\n",
    "\n",
    "Aequitas is compatible with: **Python 3.6+**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Aequitas Priorities\n",
    "- **Flexibility:** Use Aequitas in the way that makes the most sense for your existing processes. Pass model results as a Python dataframe; in CSV format via Python API, [web application](http://aequitas.dssg.io/), upload a CSV of model results to the Aequitas or the [CLI](https://dssg.github.io/aequitas/CLI.html); or from database tables defined in a [configuration YAML](https://dssg.github.io/aequitas/CLI.html) via CLI. \n",
    "\n",
    "- **Customization:** The relevant bias and fairness metrics change depending on the type of project or intervention you're planning for. Configure Aequitas to generate the metrics and visualizations most important to your analyses, or choose view all calculated bias metrics.\n",
    "\n",
    "- **Clarity:** Aequitas provides a full picture of commonly used bias metrics in your models, how they differ across groups (disparities), and contextual information on the statistical significance of each calculated disparity. Visualization methods allow for rapid comparison between groups and models."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='getting_started'></a>\n",
    "\n",
    "# Getting started with *aequitas-report* \n",
    "\n",
    "With aequitas-report uncovering bias is as simple as running a single command on a csv.\n",
    "\n",
    "\n",
    "## Input machine learning predictions\n",
    "\n",
    "After [installing on your computer](./installation.html)\n",
    "\n",
    "Run `aequitas-report` on [COMPAS data](https://github.com/dssg/aequitas/tree/master/examples): \n",
    "```\n",
    "aequitas-report --input compas_for_aequitas.csv\n",
    "```\n",
    "\n",
    "\n",
    "| score     | label_value| race | sex | age_cat |\n",
    "| --------- |------------| -----| --- | ------- |\n",
    "|   0       | 1          | African-American | Male | 25 - 45 |\n",
    "|   1       | 1          | Native American | Female | Less than 25 |\n",
    "\n",
    "\n",
    "Input data has slightly different requirements depending on whether you are using Aequitas via the webapp, CLI or Python package. In general, input data is a single table with the following columns:\n",
    "\n",
    "- `score`\n",
    "- `label_value` (for error-based metrics only)\n",
    "- at least one attribute e.g. `race`, `sex` and `age_cat` (attribute categories defined by user)\n",
    "\n",
    "Find specific input data requirements for [Python API](#python_input), [web app](#webapp_input), and [CLI](#cli_input) below.\n",
    "\n",
    "Additionally, disparity is always defined in relation to a reference group. By default, Aequitas uses majority as the reference. [Defining a reference group](./config.html)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get bias measures tailored to your problem\n",
    "\n",
    "### The Bias Report output\n",
    "\n",
    "The Bias Report produces a pdf that returns descriptive interpretation of the results along with three sets of tables. \n",
    "\n",
    "* Fairness Measures Results\n",
    "* Bias Metrics Results\n",
    "* Group Metrics Results\n",
    "\n",
    "Additionally, a csv is produced that contains the relevant data. More information about output [here](./output_data.html).\n",
    "\n",
    "### Commandline output\n",
    "\n",
    "In the command line you will see The Bias Report, which returns counts for each attribute by group and then computes various fairness metrics. This is the same information that is captured in the csv output. \n",
    "\n",
    "\n",
    "```\n",
    "\n",
    "                    \n",
    "                    ___                    _ __            \n",
    "                   /   | ___  ____ ___  __(_) /_____ ______\n",
    "                  / /| |/ _ \\/ __ `/ / / / / __/ __ `/ ___/\n",
    "                 / ___ /  __/ /_/ / /_/ / / /_/ /_/ (__  ) \n",
    "                /_/  |_\\___/\\__, /\\__,_/_/\\__/\\__,_/____/  \n",
    "                              /_/                          \n",
    "\n",
    "\n",
    "\n",
    "____________________________________________________________________________\n",
    "\n",
    "                      Bias and Fairness Audit Tool\n",
    "____________________________________________________________________________\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "Welcome to Aequitas-Audit\n",
    "Fairness measures requested: Statistical Parity,Impact Parity,FDR Parity,FPR Parity,FNR Parity,FOR Parity\n",
    "model_id, score_thresholds 1 {'rank_abs': [3317]}\n",
    "COUNTS::: race\n",
    "African-American    3696\n",
    "Asian                 32\n",
    "Caucasian           2454\n",
    "Hispanic             637\n",
    "Native American       18\n",
    "Other                377\n",
    "dtype: int64\n",
    "COUNTS::: sex\n",
    "Female    1395\n",
    "Male      5819\n",
    "dtype: int64\n",
    "COUNTS::: age_cat\n",
    "25 - 45            4109\n",
    "Greater than 45    1576\n",
    "Less than 25       1529\n",
    "dtype: int64\n",
    "audit: df shape from the crosstabs: (11, 26)\n",
    "get_disparity_major_group()\n",
    "number of rows after bias majority ref group: 11\n",
    "Any NaN?:  False\n",
    "bias_df shape: (11, 38)\n",
    "Fairness Threshold: 0.8\n",
    "Fairness Measures: ['Statistical Parity', 'Impact Parity', 'FDR Parity', 'FPR Parity', 'FNR Parity', 'FOR Parity']\n",
    "\n",
    "... \n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Getting Started with Input Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='cli_input'></a>\n",
    "\n",
    "### Input data for CLI\n",
    "\n",
    "The CLI accepts csv files and also accomodates database calls defined in Configuration files.\n",
    "\n",
    "![](_static/CLI_input.jpg)\n",
    "\n",
    "#### `score`\n",
    "By default, Aequitas CLI assumes the `score` column is a binary decision (0 or 1). Alternatively, the `score` column can contain the score (e.g. the output from a logistic regression applied to the data). In this case, the user sets a threshold to determine the binary decision. See [configurations](./config.html) for more on thresholds.\n",
    "\n",
    "#### `label_value`\n",
    "\n",
    "As with the webapp, this is the ground truth value of a binary decision. The data must be binary 0 or 1.\n",
    "\n",
    "#### attributes e.g. `race`, `sex`, `age`,`income`\n",
    "\n",
    "Group columns can be categorical or continuous. If categorical, Aequitas will produce crosstabs with bias metrics for each group_level. If continuous, Aequitas will first bin the data into quartiles.\n",
    "\n",
    "#### `model_id`\n",
    "\n",
    "`model_id` is an identifier tied to the output of a specific model. With a `model_id` column you can test the bias of multiple models at once. This feature is available using the CLI or the Python package.\n",
    "\n",
    "\n",
    "#### Reserved column names:\n",
    "\n",
    "* `id`\n",
    "* `model_id`\n",
    "* `entity_id`\n",
    "* `rank_abs`\n",
    "* `rank_pct`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='python_input'></a>\n",
    "\n",
    "### Input data for Python package\n",
    "\n",
    "Python input data can be handled identically to CLI by using `preprocess_input_df()`. Otherwise, you must discretize continuous attribute columns prior to passing the data to `Group().get_crosstabs()`.\n",
    "\n",
    "```{python}\n",
    "\n",
    "from Aequitas.preprocessing import preprocess_input_df()\n",
    "\n",
    "# *input_data* matches CLI input data norms.\n",
    "df, _ = preprocess_input_df(*input_data*)\n",
    "\n",
    "```\n",
    "![](_static/python_input.jpg)\n",
    "\n",
    "\n",
    "#### `score`\n",
    "By default, Aequitas CLI assumes the `score` column is a binary decision (0 or 1). Alternatively, the `score` column can contain the score (e.g. the output from a logistic regression applied to the data). In this case, the user sets a threshold to determine the binary decision. See [configurations](./config.html) for more on thresholds. Threshholds are set in a dictionary passed to `get_crosstabs()`.\n",
    "\n",
    "#### `label_value`\n",
    "As with the webapp, this is the ground truth value of a binary decision. The data must be binary 0 or 1.\n",
    "\n",
    "#### attributes e.g. `race`, `sex`, `age`,`income` \n",
    "\n",
    "Group columns can be categorical or continuous. If categorical, Aequitas will produce crosstabs with bias metrics for each group_level. If continuous, Aequitas will first bin the data into quartiles.\n",
    "\n",
    "If you plan to bin or discritize continuous features manually, note that `get_crosstabs()` expects attribute columns to be type string. This excludes pandas 'categorical' data type, which is the default output of certain pandas discritizing functions. You can recast 'categorical' columns to strings as follows:\n",
    "\n",
    "```\n",
    "df['categorical_type'] = df['categorical_type'].astype(str)\n",
    "```\n",
    "\n",
    "#### `model_id`\n",
    "\n",
    "`model_id` is an identifier tied to the output of a specific model. With a `model_id` column you can test the bias of multiple models at once. This feature is available using the CLI or the Python package.\n",
    "\n",
    "#### Reserved column names:\n",
    "\n",
    "* `id`\n",
    "* `model_id`\n",
    "* `entity_id`\n",
    "* `rank_abs`\n",
    "* `rank_pct`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='webapp_input'></a>\n",
    "\n",
    "### Input data for Webapp\n",
    "\n",
    "The webapp requires a single CSV with columns for a binary `score`, a binary `label_value` and an arbitrary number of attribute columns. Each row is associated with a single observation.\n",
    "\n",
    "![](_static/webapp_input.jpg)\n",
    "\n",
    "#### `score`\n",
    "\n",
    "Aequitas webapp assumes the `score` column is a binary decision (0 or 1).\n",
    "\n",
    "#### `label_value`\n",
    "\n",
    "This is the ground truth value of a binary decision. The data again must be binary 0 or 1.\n",
    "\n",
    "#### attributes e.g. `race`, `sex`, `age`,`income`\n",
    "\n",
    "Group columns can be categorical or continuous. If categorical, Aequitas will produce crosstabs with bias metrics for each group_level. If continuous, Aequitas will first bin the data into quartiles and then create crosstabs with the newly defined categories."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Return to Getting Started](#getting_started)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
