{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6uOFdSDTdl15"
      },
      "source": [
        "\n",
        "<center><img src=\"https://raw.githubusercontent.com/dssg/aequitas/master/docs/_images/aequitas_logo.svg\" width=\"450\"></center>\n",
        "\n",
        "Aequitas Flow is an open-source project for **research data scientists** and **practitioners** to experiment with Fair ML and aid in finding the best models or methods for a given dataset with fairness concerns.\n",
        "\n",
        "In this notebook, we will **perform an experiment** in **Aequitas Flow**.\n",
        "\n",
        "The steps for this end are:\n",
        "1. Define and configure the included methods in the experiment.\n",
        "2. Configure the dataset or datasets in the experiment.\n",
        "3. Configure the experiment parameters.\n",
        "4. Run the experiment.\n",
        "5. Read and visualize the final results.\n",
        "\n",
        "The objective of this project is to **standardize** and **democratize** the usage of FairML methods. This is done by abstracting several boilerplate code, such as dataset loading and spliting, method instantiation, fitting and predicting, and hyperparameter optimization into a common and easy-to-use interface. This culminates in the configuration and running of an Aequitas Flow `Experiment`.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vF0OZVeytcaB"
      },
      "source": [
        "We will start off by installing the adequate version of the `aequitas` package in the Colab runtime environment. This is common to all notebooks in the package ran in Colab."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uq1ZpYe-tIKh"
      },
      "outputs": [],
      "source": [
        "# Install Aequitas and Fairflow (TODO: change to release version afterwards)\n",
        "!pip install \"aequitas==1.0.0\" &> /dev/null\n",
        "# This only needs to run once, or after you lose your runtime environment in Colab"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZTbzpvFvuwWG"
      },
      "outputs": [],
      "source": [
        "# Cleaning the default logger of Google Colab (logs appear repeated otherwise)\n",
        "from aequitas.flow.utils.logging import clean_handlers\n",
        "\n",
        "clean_handlers()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "X-Yx8jsFV7RW"
      },
      "source": [
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QXk8_jbLVEgl"
      },
      "source": [
        "## FairML Methods\n",
        "\n",
        "In Fairflow, methods are the algorithms implemented for the solution of FairML problems. These are separated into **three different** categories, depending on the main tasks they perform:\n",
        "\n",
        "- **Pre-processing** methods alter the input data.\n",
        "- **In-processing** methods score the input data.  (Making a new category for a base estimator / model?)\n",
        "- **Post-processing** methods transform the input scores.\n",
        "\n",
        "All methods, independently of the category they are included in, have a fitting step.\n",
        "\n",
        "Let's see how to **create a configuration** a generic method. First, we have to specify the **classpath** for the method. We can check the implemented methods in Fairflow [in the official documentation](). Then, we have to specify specific **arguments** which will be used in the experiment for sampling. The prototype of a configuration should follow this format:"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Z-1ysVz9cSnr"
      },
      "source": [
        "##### **`method_config.yaml`**\n",
        "```yaml\n",
        "<method_name>:\n",
        "    classpath: <python.path.to.Class>\n",
        "    args:\n",
        "        <arg_1>:  # Categorical argument\n",
        "            - <cat_value_1>\n",
        "            - <cat_value_2>\n",
        "            - ...\n",
        "            - <cat_value_n>\n",
        "        <arg_2>:\n",
        "            type: int  # Numerical argument (int)\n",
        "            range: [1, 10]  # Range of possible values\n",
        "            log: False  # Sample from uniform distribution\n",
        "        <arg_3>:\n",
        "            type: float  # Numerical argument (float)\n",
        "            range: [0.01, 1]\n",
        "            log: True  # sample from log-uniform distribution\n",
        "        ...\n",
        "        <arg_n>:\n",
        "            - True  # We want a fixed value of True in this arg.\n",
        "```\n",
        "\n",
        "We provide examples of configurations in a python dictionaries bellow.\n",
        "\n",
        "Note that the package accepts configurations in both `.yaml` and python `dict` format.\n",
        "\n",
        "We will be creating configurations in the dictionary format for:\n",
        "\n",
        "- **LightGBM**\n",
        "- **FairGBM** (in-)\n",
        "- **Sampling** (pre-) **+ Random Forest**\n",
        "- **Logistic Regression + Thresholding** (post-)\n",
        "\n",
        "In this example, we will have a mix of pre-, in-, and post-processing FairML techniques. We will also train LightGBM models, which maximize only performance."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GfXQ4-A_XoI8"
      },
      "outputs": [],
      "source": [
        "lightgbm_config = {\n",
        "    'lightgbm': {\n",
        "        'classpath': 'aequitas.flow.methods.base_estimator.lightgbm.LightGBM',\n",
        "        'args': {\n",
        "            'boosting_type': ['dart', 'gbdt'],\n",
        "            'enable_bundle': [False,],\n",
        "            'n_estimators': {'type': 'int', 'range': [10, 100]},\n",
        "            'min_child_samples': {'type': 'int', 'range': [1, 500], 'log': True},\n",
        "            'learning_rate': {'type': 'float', 'range': [0.001, 0.1]},\n",
        "            'random_state': [42,],\n",
        "        }\n",
        "    }\n",
        "}\n",
        "\n",
        "fairgbm_config = {\n",
        "    'fairgbm': {\n",
        "        'classpath': 'aequitas.flow.methods.inprocessing.fairgbm.FairGBM',\n",
        "        'args': {\n",
        "            'global_constraint_type': ['FPR,FNR'],\n",
        "            'global_target_fpr': [0.05],\n",
        "            'global_target_fnr': {'type': 'float', 'range': [0.4, 0.6]},\n",
        "            'constraint_type': ['fpr'],\n",
        "            'constraint_fpr_threshold': [0],\n",
        "            'proxy_margin': [1],\n",
        "            'multiplier_learning_rate': {'type': 'float', 'range': [0.00001, 1.0], 'log': True},\n",
        "            'constraint_stepwise_proxy': 'cross_entropy',\n",
        "            'boosting_type': ['dart', 'gbdt'],\n",
        "            'enable_bundle': [False,],\n",
        "            'n_estimators': {'type': 'int', 'range': [10, 100]},\n",
        "            'min_child_samples': {'type': 'int', 'range': [1, 500], 'log': True},\n",
        "            'learning_rate': {'type': 'float', 'range': [0.001, 0.1]},\n",
        "            'random_state': [42,]\n",
        "        }\n",
        "    }\n",
        "}\n",
        "\n",
        "sampling_config = {\n",
        "    'sampling': {\n",
        "        'classpath': 'aequitas.flow.methods.preprocessing.PrevalenceSampling',\n",
        "        'args': {}\n",
        "    }\n",
        "}\n",
        "\n",
        "random_forest_config = {\n",
        "    'random_forest': {\n",
        "        'classpath': 'aequitas.flow.methods.base_estimator.random_forest.RandomForest',\n",
        "        'args': {\n",
        "            'n_estimators': {'type': 'int', 'range': [10, 100]},\n",
        "            'min_samples_leaf': {'type': 'int', 'range': [1, 500], 'log': True},\n",
        "            'random_state': [42,]\n",
        "        }\n",
        "    }\n",
        "}\n",
        "\n",
        "group_threshold_config = {\n",
        "    'group_threshold': {\n",
        "        'classpath': 'aequitas.flow.methods.postprocessing.GroupThreshold',\n",
        "        'args': {\n",
        "            'threshold_type': 'fpr',\n",
        "            'threshold_value': 0.05,\n",
        "        }\n",
        "    }\n",
        "}\n",
        "\n",
        "logistic_regression_config = {\n",
        "    'logistic_regression': {\n",
        "        'classpath': 'aequitas.flow.methods.base_estimator.logistic_regression.LogisticRegression',\n",
        "        'args': {\n",
        "            'penalty': ['l2', None],\n",
        "            'tol': {'type': 'float', 'range': [1e-5, 1], 'log': True},\n",
        "            'C': {'type': 'float', 'range': [1e-5, 1e2], 'log': True},\n",
        "            'random_state': [42, ]\n",
        "        }\n",
        "    }\n",
        "}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-qxx59neZ6IG"
      },
      "source": [
        "One important aspect of Fairflow is the combination of different types of methods to create a single method where the **transformation** of input data is done by the **pre-processing** method, the scoring of the data is done by the **in-processing** method, and the transformation of scores is done by the **post-processing** method. To do so, we must create an additional configuration which calls the different methods' configurations.\n",
        "##### **`composed_method_config.yaml`**\n",
        "```yaml\n",
        "<composed_method_name>:\n",
        "    type: \"pre, in, post-processing\"\n",
        "\n",
        "defaults:\n",
        "    <composed_method_name>/preprocessing: <preprocessing_method>\n",
        "    <composed_method_name>/inprocessing: <inprocessing_method>\n",
        "    <composed_method_name>/postprocessing: <postprocessing_method>\n",
        "```\n",
        "\n",
        "For this configuration, the composed method will fetch the hyperparameter search space for all of the methods, relative to itself. So, for example, if the path for the config is `~/composed_method_config.yaml`, the package expects to exist the files:\n",
        "-  `~/<composed_method_name>/preprocessing/<preprocessing_method>.yaml`\n",
        "-  `~/<composed_method_name>/inprocessing/<inprocessing_method>.yaml`\n",
        "-  `~/<composed_method_name>/postprocessing/<postprocessing_method>.yaml`\n",
        "\n",
        "\n",
        "Note that for these methods, only an in-processing method is required. If the pre-processing or post-processing methods are omited, the transformation of the input data and scores is skipped, respectively.\n",
        "\n",
        "Let's see how to do this in a python dictionary, with the previously created methods."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "27570_d7v9rG"
      },
      "outputs": [],
      "source": [
        "composed_config_lgbm = {'lightgbm':\n",
        "  {\n",
        "    'inprocessing': lightgbm_config,\n",
        "    'type': 'base estimator',\n",
        "  },\n",
        "}\n",
        "\n",
        "composed_config_fairgbm = {'fairgbm':\n",
        "  {\n",
        "    'inprocessing': fairgbm_config,\n",
        "    'type': 'in-processing',\n",
        "  },\n",
        "}\n",
        "\n",
        "composed_config_random_forest = {'Random Forest + Undersampling':\n",
        "  {\n",
        "    'preprocessing': sampling_config,\n",
        "    'inprocessing': random_forest_config,\n",
        "    'type': 'pre-processing',\n",
        "  },\n",
        "}\n",
        "\n",
        "composed_config_logistic_regression = {'Logistic Regression':\n",
        "  {\n",
        "    'inprocessing': logistic_regression_config,\n",
        "    'postprocessing': group_threshold_config,\n",
        "    'type': 'post-processing',\n",
        "  },\n",
        "}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SkRI5cLVaJLp"
      },
      "source": [
        "---\n",
        "\n",
        "## Datasets\n",
        "\n",
        "We will now **configure** a dataset to be used.\n",
        "\n",
        "These follow a pattern similar to the methods, with **classpath**, **arguments**, and an additional keyword related to the **thresholding rule**.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QWj82Y7xheew"
      },
      "source": [
        "##### **`dataset.yaml`**\n",
        "```yaml\n",
        "    <dataset_name>:\n",
        "    classpath: <python.path.to.Class>\n",
        "    threshold:\n",
        "        threshold_type: <type_of_threshold>\n",
        "        threshold_value: <value>\n",
        "    args:\n",
        "        <arg_1>: <val_1>\n",
        "        <arg_2>: <val_2>\n",
        "        ...\n",
        "        <arg_n>: <val_n>\n",
        "```\n",
        "\n",
        "In this notebook, we will use a sample of the Bank Account Fraud dataset. In this dataset, the objective is to determine if a given individual made a fraudulent attempt at opening a bank account (positive instance).\n",
        "\n",
        "Here, we must define the dataset variant in the keyword arguments for the class, passed in the **args** key. This determines the dataset that will be selected.\n",
        "\n",
        "Note that it this this configuration you should change to try a different dataset, including user-defined ones."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "h45BwSViyeOb"
      },
      "outputs": [],
      "source": [
        "baf_sample_config = {\n",
        "    'baf_sample': {\n",
        "        'classpath': 'aequitas.flow.datasets.BankAccountFraud',\n",
        "        'threshold': {\n",
        "            'threshold_type': 'fpr',\n",
        "            'threshold_value': 0.05,\n",
        "        },\n",
        "        'args': {'variant': 'Sample'},\n",
        "    }\n",
        "}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EAIob4rn5v_f"
      },
      "source": [
        "---\n",
        "## Experiment\n",
        "\n",
        "Finally, we can create a configuration for the experiment. This constitutes a simple configuration, with the number of trials per algorithm to try, the datasets, and the algorithms themselves. We can create paralel jobs to train\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Cvb7-xlv-wCv"
      },
      "source": [
        "##### **`experiment.yaml`**\n",
        "```yaml\n",
        "optimization:\n",
        "  n_trials: <trials_per_method>\n",
        "  n_jobs: <paralel_jobs>\n",
        "  sampler: <optuna_sampler>\n",
        "  sampler_args:\n",
        "    <arg_1>: <val_1>\n",
        "    <arg_2>: <val_2>\n",
        "    ...\n",
        "    <arg_n>: <val_n>\n",
        "    \n",
        "datasets:\n",
        "  - <dataset_1>\n",
        "  - <dataset_2>\n",
        "  ...\n",
        "  - <dataset_n>\n",
        "\n",
        "methods:\n",
        "  - <method_1>\n",
        "  - <method_2>\n",
        "  ...\n",
        "  - <method_n>\n",
        "```\n",
        "\n",
        "The configuration for experiments shares the same property of the `composed_methods` in which it will read configurations linked to some of the fields, in this case `datasets` and `methods`. To this end, the configurations of these components **must be** in a directory at the same level of the experiment configuration. For example, if the experiment file is in `~/experiment.yaml`, then the datasets file must be in `~/datasets/<dataset_1>.yaml`, and so on. The same applies to methods, as they should be in `~/methods/<method_1>.yaml`, and so on.\n",
        "\n",
        "The config can also be defined as a dictionary, as shown bellow."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ip4AapYwv_6E"
      },
      "outputs": [],
      "source": [
        "config = {\n",
        "  'optimization': {\n",
        "      'n_trials': 50,  # Number of runs per algorithm.\n",
        "      'n_jobs': 1,\n",
        "      'sampler': 'RandomSampler',  # The sampler for hyperparameters.\n",
        "      'sampler_args': {'seed': 42},\n",
        "  },\n",
        "  'datasets': [baf_sample_config],\n",
        "  'methods': [composed_config_lgbm, composed_config_fairgbm, composed_config_logistic_regression, composed_config_random_forest],\n",
        "}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1pSsQYCJcx2O"
      },
      "source": [
        "You can see the example from all the configurations above as `yaml` if you download the examples cell bellow. This will be available in the directory `examples/configs/colab_configs`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BPcoTcDaCCCu",
        "outputId": "68370a94-be43-4ec7-e87e-e34d413cac67"
      },
      "outputs": [],
      "source": [
        "# This cell will download a model from the repository. You do not need to run it if you have your won model.\n",
        "from aequitas.flow.utils.colab import get_examples\n",
        "\n",
        "get_examples(\"configs\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wEpexWx8DnE9"
      },
      "source": [
        "---\n",
        "#### Instantiating the Experiment\n",
        "\n",
        "Now, with the configurations correctly set, all that is left to do is instantiating an `Experiment` object with the configurations, and running it."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bEZghAhuQCtY",
        "outputId": "10caa4b4-c3d1-4c7d-aeb6-839ca6bfbf6a"
      },
      "outputs": [],
      "source": [
        "from aequitas.flow.experiment import Experiment\n",
        "from pathlib import Path\n",
        "from omegaconf import DictConfig\n",
        "\n",
        "experiment = Experiment(config=DictConfig(config), name=\"baf_exp\")\n",
        "\n",
        "experiment.run()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dCpQv33oCw4V"
      },
      "source": [
        "Note that it is possible to run a pre-defined grid and number of trials with the `DefaultExperiment` class."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QLlus1qgfOY3"
      },
      "source": [
        "We can now check some of the results from the experiment we ran."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HkIRFoWaoTiK"
      },
      "outputs": [],
      "source": [
        "from aequitas.flow.utils.results import read_results\n",
        "\n",
        "from pathlib import Path\n",
        "\n",
        "results = read_results(Path(\"artifacts/baf_exp\"))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fYDQuLOhbEi_"
      },
      "outputs": [],
      "source": [
        "# Some of the models aren't able to reach the target 5% FPR\n",
        "# We will filter these results out, with a slack of +/-2% FPR\n",
        "dataset_results = results[\"baf_sample\"]\n",
        "\n",
        "for method, method_results in dataset_results.items():\n",
        "    filtered_method_results = []\n",
        "    for iteration in method_results:\n",
        "        if 0.03 < iteration.validation_results[\"fpr\"] < 0.07:  # Here we implement the slack\n",
        "            filtered_method_results.append(iteration)\n",
        "    dataset_results[method] = filtered_method_results\n",
        "\n",
        "results[\"baf_sample\"] = dataset_results"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 636
        },
        "id": "rXy9WtcnzlLF",
        "outputId": "1a99e678-c635-422a-e393-d0ae491d13e0"
      },
      "outputs": [],
      "source": [
        "from aequitas.flow.plots.pareto import Plot\n",
        "\n",
        "plot = Plot(\n",
        "    results,\n",
        "    \"baf_sample\",\n",
        "    \"Predictive Equality\",\n",
        "    \"TPR\",\n",
        "    split=\"validation\"\n",
        ")\n",
        "\n",
        "plot.visualize()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eByCztQxfUpA"
      },
      "source": [
        "Or perform a bias audit to a specific model in the results."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 299
        },
        "id": "ZkR5j1CsG1xU",
        "outputId": "b45d284c-e1f9-420c-edf9-5186a82908fc"
      },
      "outputs": [],
      "source": [
        "from aequitas.flow.datasets import BankAccountFraud\n",
        "\n",
        "dataset = BankAccountFraud(\"Sample\")\n",
        "dataset._download = False\n",
        "dataset.load_data()\n",
        "dataset.create_splits()\n",
        "\n",
        "plot.bias_audit(119, dataset.test, \"customer_age_bin\", metrics=[\"fpr\"], results_path=\"artifacts/baf_exp\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zuRj096zJjv7"
      },
      "outputs": [],
      "source": [
        "plot.disparities(119, dataset.test, \"customer_age_bin\", metrics=[\"fpr\"], results_path=\"artifacts/baf_exp\")"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.10.13"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
